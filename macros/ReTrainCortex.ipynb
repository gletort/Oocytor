{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dc1342-567c-401f-a0ce-2491adc18452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, GlobalAveragePooling2D, UpSampling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import skimage as sk\n",
    "from skimage import util\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import skimage.io as io\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d20cf",
   "metadata": {},
   "source": [
    "### Functions to load/prepare data, data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c08c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alldatas(DIR, IMG_SIZE, aug=2, piv=0):\n",
    "    ''' \n",
    "        Select and load imgs\n",
    "        resize to IMG_SIZE data. \n",
    "        aug: do data augmentation\n",
    "        piv: amount of images flips to diversify (0 no flip - 4 always flip), useful if no augmentation\n",
    "        input data directory DIR must have subfolders \"input\" and \"mask\" with the raw images and binary files, with same names\n",
    "    '''\n",
    "    train_data = []\n",
    "    cdir = DIR+'/input'\n",
    "    mdir = DIR+'/mask'\n",
    "    for img in os.listdir(cdir):\n",
    "        ## open input image\n",
    "        path = os.path.join(cdir,img)\n",
    "        cimg = Image.open(path)\n",
    "        cimg = cimg.convert('L')\n",
    "        cimg = cimg.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "        cimg = np.array(cimg)\n",
    "        \n",
    "        ## open corresponding mask file\n",
    "        mpath = os.path.join(mdir,img)\n",
    "        mimg = Image.open(mpath)\n",
    "        mimg = mimg.convert('L')\n",
    "        mimg = mimg.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "        mimg = np.array(mimg)\n",
    "        \n",
    "        ## empty image\n",
    "        if np.min(cimg)==np.max(cimg):\n",
    "            print(\"Something wrong in this image, all empty\")\n",
    "            print(path)\n",
    "        \n",
    "        ## applies some image flips\n",
    "        if random.randrange(4) < piv:\n",
    "            cimg = np.fliplr(cimg)\n",
    "            mimg = np.fliplr(mimg)\n",
    "        if random.randrange(4) < piv:\n",
    "            cimg = np.flipud(cimg)\n",
    "            mimg = np.flipud(mimg)\n",
    "       \n",
    "        train_data.append( [cimg, mimg, img] )\n",
    "        \n",
    "        ## Do basic data augmentation (flips, rotations)\n",
    "        if aug >= 1:\n",
    "            shift_img = np.array(cimg)\n",
    "            shift_img = np.fliplr(shift_img)\n",
    "            shift_img = np.flipud(shift_img)\n",
    "            shift_mask = np.array(mimg)\n",
    "            shift_mask = np.fliplr(shift_mask)\n",
    "            shift_mask = np.flipud(shift_mask)\n",
    "            train_data.append( [shift_img, shift_mask, img+'aug.png'] )\n",
    "            \n",
    "        if aug >= 2:\n",
    "            shift_img = np.array(cimg)\n",
    "            shift_img = np.rot90(shift_img)\n",
    "            shift_mask = np.array(mimg)\n",
    "            shift_mask = np.rot90(shift_mask)\n",
    "            train_data.append( [shift_img, shift_mask, img+'aug2.png'] )\n",
    "    \n",
    "    ## randomize the dataset    \n",
    "    shuffle(train_data)\n",
    "    shuffle(train_data)\n",
    "    return train_data\n",
    "\n",
    "def normalise(img):\n",
    "    \"\"\"\n",
    "    Min-max normalisation\n",
    "    \"\"\"\n",
    "    img = (img - img.min() )/ (img.max()-img.min())\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4fe12",
   "metadata": {},
   "source": [
    "#### Metrics to train and measure network performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31083ba7-65dd-444d-87c9-55158542e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Score prediction by measuring IOU (Intersection Over Union)\n",
    "    \"\"\"\n",
    "    y_pred_class = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold\n",
    "    tp = tf.reduce_sum(y_pred_class * y_true)\n",
    "    fp = tf.reduce_sum(tf.nn.relu(y_pred_class-y_true))\n",
    "    fn = tf.reduce_sum(tf.nn.relu(y_true-y_pred_class))\n",
    "    \n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    Also known as the intersection-over-union loss.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    Used to calculate loss during training\n",
    "    \"\"\"\n",
    "    #y_pred = K.cast(K.greater(y_pred, .5), dtype='float32')\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "    sum_ =tf.reduce_sum(y_true+y_pred, axis=(1,2))\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1-jac)*smooth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68734c54",
   "metadata": {},
   "source": [
    "#### Network implementation, training, save/load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148211fb-541a-4c93-bf3d-5377ae19ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(nameMod):\n",
    "    \"\"\"\n",
    "    Load the weights of a trained network from file\n",
    "    \"\"\"\n",
    "    json_file = open(nameMod+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(nameMod+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[mean_iou, 'accuracy'] )\n",
    "    return loaded_model\n",
    "\n",
    "def save_model(model, nameMod):\n",
    "    \"\"\"\n",
    "    Save trained model (network) to files, tensorflow format\n",
    "    \"\"\"\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(nameMod+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(nameMod+\".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "def run_model( train_imgs, train_labels, batch_size=10, epochs=2, IMG_SIZE=224):\n",
    "    \"\"\" Define and initialize the network and do the training \"\"\"\n",
    "    model = build_unet(IMG_SIZE)\n",
    "    model.fit( train_imgs, train_labels, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    return model\n",
    "\n",
    "def train_model(train_data, IMG_SIZE, batchy=1, epoch=4):\n",
    "    \"\"\"\n",
    "    Go, do the training: preprocess images, and run training\n",
    "    \"\"\"\n",
    "    train_images = np.array([normalise(i[0]) for i in train_data]).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
    "    train_mask = np.array([i[1] for i in train_data]).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
    "    train_mask = (train_mask/255)\n",
    "    train_names = np.array([i[2] for i in train_data])\n",
    "    \n",
    "    ## Run network and save\n",
    "    model = run_model( train_imgs=train_images, train_labels=train_mask, batch_size=batchy, epochs=epoch, IMG_SIZE=IMG_SIZE)\n",
    "    return [model, train_mean, train_std]\n",
    "    \n",
    "\n",
    "def conv_block( nfils, inputs):\n",
    "    \"\"\"\n",
    "    Convolution block in U-Net network: sequence of 2 convolutions and normalisation\n",
    "    \"\"\"\n",
    "    conv = Conv2D(nfils, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Conv2D(nfils, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def build_unet(IMG_SIZE):\n",
    "    \"\"\"\n",
    "    U-Net architecture, with number of initial features choosable (nfil)\n",
    "    \"\"\"\n",
    "    inputs = Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "    nfil = 8   ## cortex model\n",
    "    #nfil = 24  ## zp model\n",
    "     \n",
    "    ## Downward part of U-Net\n",
    "    conv1 =  conv_block( nfil, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 =  conv_block( nfil*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 =  conv_block( nfil*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 =  conv_block( nfil*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 =  conv_block( nfil*16, pool4)\n",
    "    \n",
    "    ## Upward part of U-Net with skip connections\n",
    "    up6 = Conv2D(nfil*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = conv_block( nfil*8, merge6 )\n",
    "    \n",
    "    up7 = Conv2D(nfil*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = conv_block( nfil*4, merge7 )\n",
    "\n",
    "    up8 = Conv2D(nfil*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = conv_block( nfil*2, merge8 )\n",
    "    \n",
    "    up9 = Conv2D(nfil*1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = conv_block( nfil*1, merge9 )\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    ### load a pretrained model, and freeze the first layers\n",
    "    pretrained_model = load_model(\"/home/gaelle/Ext/MIV/humanMovies/trainingOocytor/models/cortex/model0/resmodel0\")\n",
    "    ##pretrained_model = load_model(\"/home/gaelle/Ext/MIV/humanMovies/trainingOocytor/models/zp/run0/resmodel0\") # zp model\n",
    "    for ind in range(len(model.layers)):\n",
    "        cind = ind\n",
    "        layer = model.layers[cind]\n",
    "        pretrained_layer = pretrained_model.layers[cind]\n",
    "        layer.set_weights(pretrained_layer.get_weights())\n",
    "        if cind<3:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = jaccard_distance, metrics = [mean_iou, 'accuracy'] )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9754c57",
   "metadata": {},
   "source": [
    "# Main - Load the training data, and retrain the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3c713-73da-44da-9fdb-70a8a7cbf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training data\n",
      "True\n",
      "2.8.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 15:22:19.941714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20911 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Epoch 1/40\n",
      "57/57 [==============================] - 6s 73ms/step - loss: 3.4874 - mean_iou: 0.9636 - accuracy: 0.9720\n",
      "Epoch 2/40\n",
      "57/57 [==============================] - 4s 74ms/step - loss: 2.9604 - mean_iou: 0.9694 - accuracy: 0.9733\n",
      "Epoch 3/40\n",
      "57/57 [==============================] - 4s 74ms/step - loss: 2.6720 - mean_iou: 0.9726 - accuracy: 0.9741\n",
      "Epoch 4/40\n",
      "57/57 [==============================] - 4s 74ms/step - loss: 2.4707 - mean_iou: 0.9749 - accuracy: 0.9746\n",
      "Epoch 5/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 2.3828 - mean_iou: 0.9758 - accuracy: 0.9748\n",
      "Epoch 6/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 2.2495 - mean_iou: 0.9772 - accuracy: 0.9750\n",
      "Epoch 7/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 2.1732 - mean_iou: 0.9780 - accuracy: 0.9752\n",
      "Epoch 8/40\n",
      "57/57 [==============================] - 4s 75ms/step - loss: 2.1224 - mean_iou: 0.9785 - accuracy: 0.9753\n",
      "Epoch 9/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 2.0306 - mean_iou: 0.9795 - accuracy: 0.9754\n",
      "Epoch 10/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.9764 - mean_iou: 0.9800 - accuracy: 0.9755\n",
      "Epoch 11/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.9557 - mean_iou: 0.9802 - accuracy: 0.9756\n",
      "Epoch 12/40\n",
      "57/57 [==============================] - 4s 71ms/step - loss: 1.9470 - mean_iou: 0.9803 - accuracy: 0.9756\n",
      "Epoch 13/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.8817 - mean_iou: 0.9811 - accuracy: 0.9757\n",
      "Epoch 14/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.8426 - mean_iou: 0.9815 - accuracy: 0.9758\n",
      "Epoch 15/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.7628 - mean_iou: 0.9823 - accuracy: 0.9759\n",
      "Epoch 16/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.7056 - mean_iou: 0.9829 - accuracy: 0.9760\n",
      "Epoch 17/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.6731 - mean_iou: 0.9832 - accuracy: 0.9760\n",
      "Epoch 18/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.6415 - mean_iou: 0.9835 - accuracy: 0.9761\n",
      "Epoch 19/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.6145 - mean_iou: 0.9838 - accuracy: 0.9761\n",
      "Epoch 20/40\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 1.5577 - mean_iou: 0.9843 - accuracy: 0.9762\n",
      "Epoch 21/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.5533 - mean_iou: 0.9844 - accuracy: 0.9762\n",
      "Epoch 22/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.5519 - mean_iou: 0.9844 - accuracy: 0.9762\n",
      "Epoch 23/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.5297 - mean_iou: 0.9847 - accuracy: 0.9763\n",
      "Epoch 24/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.4922 - mean_iou: 0.9851 - accuracy: 0.9763\n",
      "Epoch 25/40\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 1.4816 - mean_iou: 0.9852 - accuracy: 0.9763\n",
      "Epoch 26/40\n",
      "10/57 [====>.........................] - ETA: 3s - loss: 1.4406 - mean_iou: 0.9856 - accuracy: 0.9763"
     ]
    }
   ],
   "source": [
    "## parameters\n",
    "path = \"/home/gaelle/Ext/MIV/humanMovies/\"\n",
    "TRAINDIR = path+\"dataGT/cortex/\"     ## directory of training data (with subfolders \"input\" and \"mask\")\n",
    "outfold = path+\"trainingOocytor/models/cortex/retrained/retrained4b/\"    ## where the retrained network will be saved\n",
    "IMG_SIZE = 256   ## size of the images in Oocytor\n",
    "nepoch = 40      ## number of retraining iterations\n",
    "\n",
    "## load data\n",
    "accur = []\n",
    "train_data = []\n",
    "print(\"Load training data\")\n",
    "train_oursinfert = load_alldatas(TRAINDIR, IMG_SIZE, 2, 3)\n",
    "for cur in train_oursinfert:\n",
    "    train_data.append(cur)    \n",
    "    shuffle(train_data)\n",
    "shuffle(train_data)\n",
    "\n",
    "## use GPU if possible\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "      #device_count = {'GPU': 0}\n",
    "    )\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "## train model\n",
    "model, train_mean, train_std = train_model(train_data, IMG_SIZE, batchy=30, epoch=nepoch)\n",
    "save_model(model, outfold+\"resmodel\"+str(count)+\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6cad2",
   "metadata": {},
   "source": [
    "#### test performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d5503b-d9d9-4070-8a4a-9a1916169031",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TESTDIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = load_model(\"/home/gaelle/Ext/MIV/models/cortex/run2/resmodel0\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#outfold = path+\"script/retrainOurs/run7/\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## test fertilized\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m load_alldatas(\u001b[43mTESTDIR\u001b[49m, IMG_SIZE, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([normalise(i[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_data])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,IMG_SIZE, IMG_SIZE,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_data])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,IMG_SIZE, IMG_SIZE,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TESTDIR' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## test fertilized\n",
    "test_data = load_alldatas(TESTDIR, IMG_SIZE, 0)\n",
    "test_images = np.array([normalise(i[0]) for i in test_data]).reshape(-1,IMG_SIZE, IMG_SIZE,1)\n",
    "test_labels = np.array([i[1] for i in test_data]).reshape(-1,IMG_SIZE, IMG_SIZE,1)\n",
    "test_names = np.array([i[2] for i in test_data])\n",
    "test_labels = test_labels/255\n",
    "loss, iou, acc = model.evaluate( test_images, test_labels, verbose=1)\n",
    "print(str(loss)+' '+str(iou)+' '+str(acc))\n",
    "resfile = open(outfold+\"test_retrained.txt\", \"w\")\n",
    "resfile.write(str(loss)+' '+str(iou)+' '+str(acc))\n",
    "resfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d32ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miv-env",
   "language": "python",
   "name": "miv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
